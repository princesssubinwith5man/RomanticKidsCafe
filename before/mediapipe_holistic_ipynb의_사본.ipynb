{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2PlazN5Q94l"
   },
   "source": [
    "Usage example of MediaPipe Holistic Solution API in Python (see also http://solutions.mediapipe.dev/holistic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AuQfLvpuJkb0",
    "outputId": "2908d08d-4fc7-43d2-e917-92772b4db5ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (0.8.9.1)\n",
      "Requirement already satisfied: matplotlib in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from mediapipe) (3.5.1)\n",
      "Requirement already satisfied: numpy in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from mediapipe) (1.21.2)\n",
      "Requirement already satisfied: opencv-contrib-python in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from mediapipe) (4.5.5.64)\n",
      "Requirement already satisfied: absl-py in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from mediapipe) (3.19.4)\n",
      "Requirement already satisfied: six in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from matplotlib->mediapipe) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from matplotlib->mediapipe) (3.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /tools/anaconda3/envs/torch/lib/python3.8/site-packages (from matplotlib->mediapipe) (4.25.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sWGG66XeRXEi"
   },
   "source": [
    "Upload any image that that has a person. We take two example images from the web: https://unsplash.com/photos/v4zceVZ5HK8 and https://unsplash.com/photos/e_rhazQLaSs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "7SwzZ1nJLWt0",
    "outputId": "f61eba9c-eb0e-4b37-d032-fab9fce35246"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[1;32m      2\u001b[0m uploaded \u001b[38;5;241m=\u001b[39m files\u001b[38;5;241m.\u001b[39mupload()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "nW2TjFyhLvVH",
    "outputId": "f678f841-6317-4667-98d3-c6c0ee2ab6fa"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cv2_imshow\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "def resize_and_show(image):\n",
    "  h, w = image.shape[:2]\n",
    "  if h < w:\n",
    "    img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "  else:\n",
    "    img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "  cv2_imshow(img)\n",
    "\n",
    "# Read images with OpenCV.\n",
    "images = {name: cv2.imread(name) for name in uploaded.keys()}\n",
    "# Preview the images.\n",
    "for name, image in images.items():\n",
    "  print(name)\n",
    "  resize_and_show(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Fso4oNqXIkp"
   },
   "source": [
    "All MediaPipe Solutions Python API examples are under mp.solutions.\n",
    "\n",
    "For the MediaPipe Pose solution, we can access this module as `mp_holistic = mp.solutions.holistic`.\n",
    "\n",
    "You may change the parameters, such as `static_image_mode` and `min_detection_confidence`, during the initialization. Run `help(mp_holistic.Holistic)` to get more informations about the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BboTB-FAMfPo",
    "outputId": "342f4166-ff77-45f6-9570-d1b9cf8bba47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Holistic in module mediapipe.python.solutions.holistic:\n",
      "\n",
      "class Holistic(mediapipe.python.solution_base.SolutionBase)\n",
      " |  Holistic(static_image_mode=False, model_complexity=1, smooth_landmarks=True, enable_segmentation=False, smooth_segmentation=True, refine_face_landmarks=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
      " |  \n",
      " |  MediaPipe Holistic.\n",
      " |  \n",
      " |  MediaPipe Holistic processes an RGB image and returns pose landmarks, left and\n",
      " |  right hand landmarks, and face mesh landmarks on the most prominent person\n",
      " |  detected.\n",
      " |  \n",
      " |  Please refer to https://solutions.mediapipe.dev/holistic#python-solution-api\n",
      " |  for usage examples.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Holistic\n",
      " |      mediapipe.python.solution_base.SolutionBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, static_image_mode=False, model_complexity=1, smooth_landmarks=True, enable_segmentation=False, smooth_segmentation=True, refine_face_landmarks=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
      " |      Initializes a MediaPipe Holistic object.\n",
      " |      \n",
      " |      Args:\n",
      " |        static_image_mode: Whether to treat the input images as a batch of static\n",
      " |          and possibly unrelated images, or a video stream. See details in\n",
      " |          https://solutions.mediapipe.dev/holistic#static_image_mode.\n",
      " |        model_complexity: Complexity of the pose landmark model: 0, 1 or 2. See\n",
      " |          details in https://solutions.mediapipe.dev/holistic#model_complexity.\n",
      " |        smooth_landmarks: Whether to filter landmarks across different input\n",
      " |          images to reduce jitter. See details in\n",
      " |          https://solutions.mediapipe.dev/holistic#smooth_landmarks.\n",
      " |        enable_segmentation: Whether to predict segmentation mask. See details in\n",
      " |          https://solutions.mediapipe.dev/holistic#enable_segmentation.\n",
      " |        smooth_segmentation: Whether to filter segmentation across different input\n",
      " |          images to reduce jitter. See details in\n",
      " |          https://solutions.mediapipe.dev/holistic#smooth_segmentation.\n",
      " |        refine_face_landmarks: Whether to further refine the landmark coordinates\n",
      " |          around the eyes and lips, and output additional landmarks around the\n",
      " |          irises. Default to False. See details in\n",
      " |          https://solutions.mediapipe.dev/holistic#refine_face_landmarks.\n",
      " |        min_detection_confidence: Minimum confidence value ([0.0, 1.0]) for person\n",
      " |          detection to be considered successful. See details in\n",
      " |          https://solutions.mediapipe.dev/holistic#min_detection_confidence.\n",
      " |        min_tracking_confidence: Minimum confidence value ([0.0, 1.0]) for the\n",
      " |          pose landmarks to be considered tracked successfully. See details in\n",
      " |          https://solutions.mediapipe.dev/holistic#min_tracking_confidence.\n",
      " |  \n",
      " |  process(self, image: numpy.ndarray) -> <class 'NamedTuple'>\n",
      " |      Processes an RGB image and returns the pose landmarks, left and right hand landmarks, and face landmarks on the most prominent person detected.\n",
      " |      \n",
      " |      Args:\n",
      " |        image: An RGB image represented as a numpy ndarray.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the underlying graph throws any error.\n",
      " |        ValueError: If the input image is not three channel RGB.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A NamedTuple with fields describing the landmarks on the most prominate\n",
      " |        person detected:\n",
      " |          1) \"pose_landmarks\" field that contains the pose landmarks.\n",
      " |          2) \"pose_world_landmarks\" field that contains the pose landmarks in\n",
      " |          real-world 3D coordinates that are in meters with the origin at the\n",
      " |          center between hips.\n",
      " |          3) \"left_hand_landmarks\" field that contains the left-hand landmarks.\n",
      " |          4) \"right_hand_landmarks\" field that contains the right-hand landmarks.\n",
      " |          5) \"face_landmarks\" field that contains the face landmarks.\n",
      " |          6) \"segmentation_mask\" field that contains the segmentation mask if\n",
      " |             \"enable_segmentation\" is set to true.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from mediapipe.python.solution_base.SolutionBase:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |      A \"with\" statement support.\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_val, exc_tb)\n",
      " |      Closes all the input sources and the graph.\n",
      " |  \n",
      " |  close(self) -> None\n",
      " |      Closes all the input sources and the graph.\n",
      " |  \n",
      " |  reset(self) -> None\n",
      " |      Resets the graph for another run.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from mediapipe.python.solution_base.SolutionBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "help(mp_holistic.Holistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kekjK-RzCPm1"
   },
   "outputs": [],
   "source": [
    "# Import drawing_utils and drawing_styles.\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "BAivyQ_xOtFp",
    "outputId": "179924d2-c22f-4efc-f801-79deaa149ef7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run MediaPipe Holistic and draw pose landmarks.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_holistic\u001b[38;5;241m.\u001b[39mHolistic(\n\u001b[1;32m      3\u001b[0m     static_image_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, model_complexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m holistic:\n\u001b[0;32m----> 4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m \u001b[43mimages\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Convert the BGR image to RGB and process it with MediaPipe Pose.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     results \u001b[38;5;241m=\u001b[39m holistic\u001b[38;5;241m.\u001b[39mprocess(cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Print nose coordinates.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "# Run MediaPipe Holistic and draw pose landmarks.\n",
    "with mp_holistic.Holistic(\n",
    "    static_image_mode=True, min_detection_confidence=0.5, model_complexity=2) as holistic:\n",
    "  for name, image in images.items():\n",
    "    # Convert the BGR image to RGB and process it with MediaPipe Pose.\n",
    "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print nose coordinates.\n",
    "    image_hight, image_width, _ = image.shape\n",
    "    if results.pose_landmarks:\n",
    "      print(\n",
    "        f'Nose coordinates: ('\n",
    "        f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].x * image_width}, '\n",
    "        f'{results.pose_landmarks.landmark[mp_holistic.PoseLandmark.NOSE].y * image_hight})'\n",
    "      )\n",
    "\n",
    "    # Draw pose landmarks.\n",
    "    print(f'Pose landmarks of {name}:')\n",
    "    annotated_image = image.copy()\n",
    "    mp_drawing.draw_landmarks(annotated_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(annotated_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(\n",
    "        annotated_image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_TESSELATION,\n",
    "        landmark_drawing_spec=None,\n",
    "        connection_drawing_spec=mp_drawing_styles\n",
    "        .get_default_face_mesh_tesselation_style())\n",
    "    mp_drawing.draw_landmarks(\n",
    "        annotated_image,\n",
    "        results.pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec=mp_drawing_styles.\n",
    "        get_default_pose_landmarks_style())\n",
    "    resize_and_show(annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "vp-ohtBNSFkj",
    "outputId": "5045ce2e-badd-4594-8a18-958899405b0a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run MediaPipe Holistic and plot 3d pose world landmarks.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m  mp_holistic\u001b[38;5;241m.\u001b[39mHolistic(static_image_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m holistic:\n\u001b[0;32m----> 3\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m \u001b[43mimages\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m     results \u001b[38;5;241m=\u001b[39m holistic\u001b[38;5;241m.\u001b[39mprocess(cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Print the real-world 3D coordinates of nose in meters with the origin at\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# the center between hips.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "# Run MediaPipe Holistic and plot 3d pose world landmarks.\n",
    "with  mp_holistic.Holistic(static_image_mode=True) as holistic:\n",
    "  for name, image in images.items():\n",
    "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Print the real-world 3D coordinates of nose in meters with the origin at\n",
    "    # the center between hips.\n",
    "    print('Nose world landmark:'),\n",
    "    print(results.pose_world_landmarks.landmark[mp_holistic.PoseLandmark.NOSE])\n",
    "    \n",
    "    # Plot pose world landmarks.\n",
    "    print(f'Pose world landmarks of {name}:')\n",
    "    mp_drawing.plot_landmarks(\n",
    "        results.pose_world_landmarks, mp_holistic.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "id": "_cOBhQbfh2DQ",
    "outputId": "05f43072-3802-4ddf-e966-c8f65da8930a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run MediaPipe Holistic with `enable_segmentation=True` to get pose segmentation.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_holistic\u001b[38;5;241m.\u001b[39mHolistic(\n\u001b[1;32m      3\u001b[0m     static_image_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, enable_segmentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m holistic:\n\u001b[0;32m----> 4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m name, image \u001b[38;5;129;01min\u001b[39;00m \u001b[43mimages\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m     results \u001b[38;5;241m=\u001b[39m holistic\u001b[38;5;241m.\u001b[39mprocess(cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Draw pose segmentation.\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "# Run MediaPipe Holistic with `enable_segmentation=True` to get pose segmentation.\n",
    "with mp_holistic.Holistic(\n",
    "    static_image_mode=True, enable_segmentation=True) as holistic:\n",
    "  for name, image in images.items():\n",
    "    results = holistic.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Draw pose segmentation.\n",
    "    print(f'Pose segmentation of {name}:')\n",
    "    annotated_image = image.copy()\n",
    "    red_img = np.zeros_like(annotated_image, dtype=np.uint8)\n",
    "    red_img[:, :] = (255,255,255)\n",
    "    segm_2class = 0.2 + 0.8 * results.segmentation_mask\n",
    "    segm_2class = np.repeat(segm_2class[..., np.newaxis], 3, axis=2)\n",
    "    annotated_image = annotated_image * segm_2class + red_img * (1 - segm_2class)\n",
    "    resize_and_show(annotated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mediapipe_holistic.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
