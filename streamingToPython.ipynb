{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96401c03-f344-4db9-83e9-7fc213ab7510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time \n",
    "import ipywidgets as widgets \n",
    "import IPython.display as display \n",
    "import copy\n",
    "from ipywidgets import Video, Image\n",
    "from IPython.display import display \n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "import cv2\n",
    "import base64\n",
    "import ipywidgets as widgets\n",
    "import copy\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import IPython\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d917324b-72da-4cd1-9f06-661402b92f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://114.70.235.37:8091/?action=stream\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60d1ccac-1587-4067-a572-4f279ec99866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bc8224-fa30-4a90-afc6-dd3cab7d14c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "BG_COLOR = (192, 192, 192) # gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bae0f71-6a50-4066-acd7-5e7484a5ab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/stu1/.cache/torch/hub/ultralytics_yolov5_master\n",
      "YOLOv5 ðŸš€ 2022-5-22 Python-3.8.12 torch-1.11.0 CUDA:0 (NVIDIA GeForce RTX 3080 Ti, 12045MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/2: 720x1280 2 persons, 1 tie\n",
      "image 2/2: 1080x810 3 persons, 1 bus\n",
      "Speed: 644.6ms pre-process, 4.0ms inference, 0.7ms NMS per image at shape (2, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "model.conf = 0.6\n",
    "\n",
    "# Images\n",
    "dir = 'https://github.com/ultralytics/yolov5/raw/master/data/images/'\n",
    "imgs = [dir + f for f in ('zidane.jpg', 'bus.jpg')]  # batch of images\n",
    "\n",
    "# Inference\n",
    "results = model(imgs)\n",
    "results.print()  # or .show(), .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e58c3cc-6dca-4664-be29-4d28ac63e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as multi\n",
    "from mp_test import pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "984f7621-bd9d-4027-90cc-36685f2dc83e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7924151fe349ad861318e15f9c8432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', layout=\"Layout(border='solid')\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "vid = './before/Image/1.mp4'\n",
    "vid2 = './6-2/6-2_001-C01.mp4'\n",
    "cap = cv2.VideoCapture(vid2)\n",
    "wImg = widgets.Image( \n",
    "    layout = widgets.Layout(border=\"solid\") \n",
    ") \n",
    "display(wImg)\n",
    "pool = Pool(os.cpu_count())\n",
    "if cap.isOpened(): \n",
    "    ret, img = cap.read()\n",
    "    while ret:\n",
    "        st = time.time()\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # ë™ì˜ìƒ íŒŒì¼ì—ì„œ ìº¡ì³ëœ ì´ë¯¸ì§€ë¥¼ ì´ë¯¸ì§€ íŒŒì¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë‹¤ì‹œ ì¸ì½”ë”©ì„ í•œë‹¤. \n",
    "        results = model(img)\n",
    "        \n",
    "        # xyì—ëŠ” ì¸ì‹í•œ ê° ê°ì²´, xy ì¢Œí‘œë¡œ êµ¬ì„±ëœ ë°ì´í„° í”„ë ˆìž„ ë‹´ê¹€\n",
    "        xy = results.pandas().xyxy[0]\n",
    "        \n",
    "        # personì—ëŠ” ì¸ì‹í•œ ê°ì²´ì¤‘ 'person'ë§Œ ì¶”ì¶œ\n",
    "        person = xy[xy['name'] == 'person']\n",
    "        \n",
    "        crop_image = []\n",
    "        results_crop = []\n",
    "        # ì´ë¯¸ì§€ \n",
    "        for index, row in person.iterrows():\n",
    "            # ì´ë¯¸ì§€ì—ì„œ ì‚¬ëžŒì— í•´ë‹¹í•˜ëŠ” ë¶€ë¶„ë§Œ í¬ë¡­\n",
    "            # ì‚¬ì§„ í•œìž¥(img) -> ì‚¬ëžŒ ì‚¬ì§„ ì—¬ëŸ¬ìž¥(crop_image[])\n",
    "            crop_image.append(img[int(row['ymin']):int(row['ymax']), int(row['xmin']):int(row['xmax'])])          \n",
    "            croped = pool.map(pose,crop_image)\n",
    "            \n",
    "        for res in croped:\n",
    "            tmpStream = cv2.imencode(\".jpeg\", res)[1].tobytes()\n",
    "            wImg.value = tmpStream\n",
    "        \"\"\"\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        str = \"FPS : %0.1f\" % fps        \n",
    "        cv2.putText(img, str, (0, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255),3)\n",
    "        \"\"\"\n",
    "        ret, img = cap.read()\n",
    "else:\n",
    "    print(\"not opened\")\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dde300-33ab-4292-9ef0-ac10888c7752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98ff4f5-e0d2-402a-902e-3ce8989d2072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
