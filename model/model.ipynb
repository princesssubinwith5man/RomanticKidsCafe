{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53fdfac-882e-43b6-bf14-384d68e11c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14597f89-8c71-4284-8590-4285f0e276f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('/project/annotation/train.pt')\n",
    "test_data = torch.load('/project/annotation/test.pt')\n",
    "valid_data = torch.load('/project/annotation/valid.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c016475d-7651-4747-90de-e69416404288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "batch_size = 16\n",
    "\n",
    "# make sure to SHUFFLE for your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d328bc3b-f168-4091-ad08-54809a5beed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([16, 30, 48])\n",
      "Sample input: \n",
      " tensor([[[8.8700e+02, 8.9100e+02, 2.0000e+00,  ..., 1.0980e+03,\n",
      "          5.8400e+02, 2.0000e+00],\n",
      "         [1.0460e+03, 8.3600e+02, 2.0000e+00,  ..., 1.1770e+03,\n",
      "          5.1300e+02, 2.0000e+00],\n",
      "         [1.0580e+03, 8.4700e+02, 2.0000e+00,  ..., 1.1930e+03,\n",
      "          5.1600e+02, 2.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[9.4100e+02, 8.7200e+02, 2.0000e+00,  ..., 1.0640e+03,\n",
      "          5.3600e+02, 2.0000e+00],\n",
      "         [9.4100e+02, 8.7200e+02, 2.0000e+00,  ..., 1.0640e+03,\n",
      "          5.3600e+02, 2.0000e+00],\n",
      "         [9.4100e+02, 8.7200e+02, 2.0000e+00,  ..., 1.0640e+03,\n",
      "          5.3600e+02, 2.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[8.6900e+02, 9.2400e+02, 2.0000e+00,  ..., 8.8600e+02,\n",
      "          5.3200e+02, 2.0000e+00],\n",
      "         [9.1100e+02, 9.3400e+02, 2.0000e+00,  ..., 9.2900e+02,\n",
      "          5.9500e+02, 2.0000e+00],\n",
      "         [8.0300e+02, 9.4500e+02, 2.0000e+00,  ..., 9.1600e+02,\n",
      "          7.2500e+02, 2.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[8.3900e+02, 9.5600e+02, 2.0000e+00,  ..., 8.6800e+02,\n",
      "          5.0600e+02, 1.0000e+00],\n",
      "         [8.3900e+02, 9.5600e+02, 2.0000e+00,  ..., 8.6800e+02,\n",
      "          5.0600e+02, 1.0000e+00],\n",
      "         [8.3900e+02, 9.5600e+02, 2.0000e+00,  ..., 8.6100e+02,\n",
      "          5.3300e+02, 1.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[9.6500e+02, 8.9500e+02, 2.0000e+00,  ..., 1.0970e+03,\n",
      "          6.3800e+02, 2.0000e+00],\n",
      "         [9.6500e+02, 8.9500e+02, 2.0000e+00,  ..., 1.0750e+03,\n",
      "          5.0800e+02, 2.0000e+00],\n",
      "         [9.6500e+02, 8.9500e+02, 2.0000e+00,  ..., 1.0510e+03,\n",
      "          4.4700e+02, 2.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "        [[9.6500e+02, 8.4200e+02, 2.0000e+00,  ..., 1.0710e+03,\n",
      "          6.8100e+02, 2.0000e+00],\n",
      "         [9.6500e+02, 8.4200e+02, 2.0000e+00,  ..., 1.0710e+03,\n",
      "          6.8100e+02, 2.0000e+00],\n",
      "         [9.7300e+02, 8.4600e+02, 2.0000e+00,  ..., 1.0560e+03,\n",
      "          6.7400e+02, 2.0000e+00],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00]]])\n",
      "\n",
      "Sample label size:  torch.Size([16])\n",
      "Sample label: \n",
      " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d58f52e-8ad2-44de-abb2-d1d7a21acbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_size, output_size, hidden_dim, n_layers):\n",
    "        \n",
    "        super(SentimentLSTM, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # embedding and LSTM layers\n",
    "        self.lstm = nn.LSTM(seq_size, hidden_dim, n_layers, batch_first=True)\n",
    "        \n",
    "        # linear and sigmoid layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        lstm_out, hidden = self.lstm(x)\n",
    "        ## lstm_out.shape [batch, seq_len, hidden_dim]\n",
    "        ## hidden [batch, hidden_dim]\n",
    "\n",
    "        # fully connected layer        \n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        ## out.shape: [n_layer * n_direction, batch, output_size]\n",
    "\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc6e69a-b06e-401c-950a-e29c43f436cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 512\n",
    "n_layers = 4\n",
    "lr = 0.01\n",
    "output_size = 1\n",
    "\n",
    "model = SentimentLSTM(48, output_size, hidden_dim, n_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b3e5842-3397-4f6a-a1b1-2a178dba1946",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        # nn.init.uniform_(param.data, -0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e24a76cf-2d0c-4552-9e5c-6f4d6f10f5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentLSTM(\n",
       "  (lstm): LSTM(48, 512, num_layers=4, batch_first=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120e3df-1259-4ff3-bcfd-c8ba04fe57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.00000 valid loss:  0.00000 lr: 0.01000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 11/21 [13:11<12:01, 72.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.00000 valid loss:  0.00000 lr: 0.01000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 17/21 [20:24<04:48, 72.16s/it]"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "num_epochs = 20\n",
    "device = 'cuda'\n",
    "m = nn.Softmax(dim = 1)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs+1)): \n",
    "    # train\n",
    "\n",
    "    losses = []\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "\n",
    "        model.train()\n",
    "        outputs, hidden = model(input.to(device))\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # print(f'target shape: {target.shape}')\n",
    "        # print(f'outputs shape: {outputs.shape}')\n",
    "        # print(outputs[0])\n",
    "        # print(target[0])\n",
    "        loss = criterion(outputs, target.type(torch.long).to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        # scheduler.step()\n",
    "        # torch.nn.utils.clip_grad_norm_(lstm.parameters(), 10)\n",
    "\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    train_losses.append(np.mean(np.array(losses)))\n",
    "\n",
    "    losses = []\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "\n",
    "        model.eval()\n",
    "        valid, hidden = model(input.to(device))\n",
    "\n",
    "        #inverse\n",
    "        # valid = torch.from_numpy(scaler.inverse_transform(valid.cpu().detach().numpy()))\n",
    "\n",
    "        vall_loss = criterion(valid, target.type(torch.long).to(device))\n",
    "        # scheduler.step(vall_loss)\n",
    "        losses.append(vall_loss.item())\n",
    "\n",
    "    valid_losses.append(np.mean(np.array(losses)))\n",
    "    \n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        # print(criterion1(outputs, y_train.to(device),quantile))\n",
    "\n",
    "        print(\"Epoch: %d, loss: %1.5f valid loss:  %1.5f lr: %1.5f \" %(epoch, train_losses[-1],valid_losses[-1],\n",
    "                                                                        optimizer.param_groups[0][\"lr\"]))\n",
    "\n",
    "    torch.save(model.state_dict(), './model_weight.pth')\n",
    "    # model.load_state_dict(torch.load(SAVEPATH+'model_weight.pth'))\n",
    "\n",
    "    # early_stopping는 validation loss가 감소하였는지 확인이 필요하며,\n",
    "    # 만약 감소하였을경우 현제 모델을 checkpoint로 만든다.\n",
    "    \n",
    "    \"\"\"\n",
    "    early_stopping(round(valid_losses[-1],5), model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Epoch: %d, loss: %1.5f valid loss:  %1.5f lr: %1.5f \" %(epoch, train_losses[-1],valid_losses[-1],\n",
    "                                                                      optimizer.param_groups[0][\"lr\"]))\n",
    "        break\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8935460f-178f-4c01-bdca-1a6a3faafaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b= train_data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c947f99-5f54-4ef6-8511-e149a59b1858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e1e9f44b-e6f2-4b9d-ad6f-6fc52c790aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fbac73-da28-463e-a037-3762357ed896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b68a9e-b20a-4704-9095-68b744e0c56c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
