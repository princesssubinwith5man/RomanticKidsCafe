{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import trange\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path_dir = '/project/annotation/2D'\n",
    "file_list1 = os.listdir(path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 697/697 [01:53<00:00,  6.17it/s]\n"
     ]
    }
   ],
   "source": [
    "false_data = list()\n",
    "true_data = list()\n",
    "\n",
    "true_name = list()\n",
    "\n",
    "for file_name1 in tqdm(file_list1):\n",
    "    if(file_name1[0] == '.'):\n",
    "        file_name1 = file_name1[2:]\n",
    "    #print(file_name1)\n",
    "    file_path = path_dir + '/' + file_name1\n",
    "    \n",
    "    if 'DS_Store' in file_path:\n",
    "        continue\n",
    "\n",
    "    file_list2 = os.listdir(file_path)\n",
    "\n",
    "    if file_name1[0] == '6': # 쓰러짐 영상\n",
    "        for file_name2 in file_list2:\n",
    "            if 'DS_Store' in file_name2:\n",
    "                continue\n",
    "            if(file_name2[0] == '.'):\n",
    "                file_name2 = file_name2[2:]\n",
    "            read_file_path = file_path + '/' + file_name2\n",
    "            true_name.append(file_name2)\n",
    "\n",
    "            with open(read_file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "                #print(json_data.keys())\n",
    "                tmpList = list()\n",
    "\n",
    "                for data in json_data['annotations']:\n",
    "                    tmpList.append(data['keypoints'])\n",
    "\n",
    "                true_data.append(tmpList)\n",
    "\n",
    "    else: # 기타 영상\n",
    "        for file_name2 in file_list2:\n",
    "            if 'DS_Store' in file_name2:\n",
    "                continue\n",
    "            if(file_name2[0] == '.'):\n",
    "                file_name2 = file_name2[2:]\n",
    "            read_file_path = file_path + '/' + file_name2\n",
    "\n",
    "    \n",
    "            with open(read_file_path, 'r') as f:\n",
    "                json_data = json.load(f)\n",
    "                #print(json_data.keys())\n",
    "                tmpList = list()\n",
    "                for data in json_data['annotations']:\n",
    "                    tmpList.append(data['keypoints'])\n",
    "\n",
    "                false_data.append(tmpList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for index, data in enumerate(true_data):\n",
    "    if len(data) < 30:\n",
    "        tmp_list = [[0 for w in range(48)] for h in range(30-len(data))]\n",
    "        data += tmp_list\n",
    "        true_data[index]=data\n",
    "    else:\n",
    "        true_data[index] = data[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, data in enumerate(false_data):\n",
    "    if len(data) < 30:\n",
    "        tmp_list = [[0 for w in range(48)] for h in range(30-len(data))]\n",
    "        data += tmp_list\n",
    "        false_data[index]=data\n",
    "    else:\n",
    "        false_data[index] = data[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_np = np.array(true_data, dtype=np.float32)\n",
    "false_np = np.array(false_data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(793340, 30, 48)\n",
      "(15324, 30, 48)\n"
     ]
    }
   ],
   "source": [
    "del(true_data)\n",
    "del(false_data)\n",
    "\n",
    "print(false_np.shape)\n",
    "print(true_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([1 for w in range(len(true_np))])\n",
    "y_false = np.array([0 for w in range(len(false_np))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.concatenate((false_np, true_np), axis=0)\n",
    "data_y = np.concatenate((y_false, y_true), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(data_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "split_idx = int(len(data_x)*0.8)\n",
    "train_x, remaining_x = data_x[:split_idx], data_x[split_idx:]\n",
    "train_y, remaining_y = data_y[:split_idx], data_y[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 16\n",
    "\n",
    "# make sure to SHUFFLE for your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('train.pt')\n",
    "test_data = torch.load('test.pt')\n",
    "valid_data = torch.load('valid.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
