{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b53fdfac-882e-43b6-bf14-384d68e11c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad04167d-8ea1-4b7a-b1ab-057e12a6a03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14597f89-8c71-4284-8590-4285f0e276f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.load('/project/annotation/train_mul.pt')\n",
    "test_data = torch.load('/project/annotation/test_mul.pt')\n",
    "valid_data = torch.load('/project/annotation/valid_mul.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c016475d-7651-4747-90de-e69416404288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "batch_size = 32\n",
    "device='cuda'\n",
    "\n",
    "# make sure to SHUFFLE for your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d328bc3b-f168-4091-ad08-54809a5beed6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d58f52e-8ad2-44de-abb2-d1d7a21acbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, seq_size, output_size, hidden_dim, n_layers):\n",
    "        \n",
    "        super(SentimentLSTM, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # embedding and LSTM layers\n",
    "        self.lstm = nn.LSTM(seq_size, hidden_dim, n_layers, batch_first=True, dropout=0.2)\n",
    "        \n",
    "        # linear and sigmoid layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        lstm_out, hidden = self.lstm(x)\n",
    "        ## lstm_out.shape [batch, seq_len, hidden_dim]\n",
    "        ## hidden [batch, hidden_dim]\n",
    "\n",
    "        # fully connected layer        \n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        ## out.shape: [n_layer * n_direction, batch, output_size]\n",
    "\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc6e69a-b06e-401c-950a-e29c43f436cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        # nn.init.uniform_(param.data, -0.1, 0.1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b3e5842-3397-4f6a-a1b1-2a178dba1946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentLSTM(\n",
       "  (lstm): LSTM(32, 512, num_layers=4, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_dim = 512\n",
    "n_layers = 4\n",
    "lr = 0.01\n",
    "output_size = 1\n",
    "\n",
    "model = SentimentLSTM(32, output_size, hidden_dim, n_layers)\n",
    "model.to('cuda')\n",
    "model.apply(init_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24a76cf-2d0c-4552-9e5c-6f4d6f10f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = torch.nn.BCELoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f120e3df-1259-4ff3-bcfd-c8ba04fe57a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1/11 [02:07<21:19, 127.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.67410 valid loss:  0.66610 lr: 0.01000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 3/11 [06:25<17:08, 128.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 0.67257 valid loss:  0.65886 lr: 0.01000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 4/11 [08:55<15:36, 133.81s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# scheduler.step()\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(lstm.parameters(), 10)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     32\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39marray(losses)))\n",
      "File \u001b[0;32m/tools/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tools/anaconda3/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tools/anaconda3/lib/python3.9/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/tools/anaconda3/lib/python3.9/site-packages/torch/optim/_functional.py:105\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    103\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    109\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[1;32m    110\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "valid_losses = []\n",
    "num_epochs = 10\n",
    "device = 'cuda'\n",
    "m = nn.Softmax(dim = 1)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs+1)): \n",
    "    # train\n",
    "\n",
    "    losses = []\n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "        inputs, target = inputs.cuda(), target.cuda()\n",
    "\n",
    "        model.train()\n",
    "        model.\n",
    "        outputs, hidden = model(inputs)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        # print(f'target shape: {target.shape}')\n",
    "        # print(f'outputs shape: {outputs.shape}')\n",
    "        # print(outputs[0])\n",
    "        # print(target[0])\n",
    "        loss = criterion(outputs.squeeze(), target.float())\n",
    "        loss.backward()\n",
    "\n",
    "        # scheduler.step()\n",
    "        # torch.nn.utils.clip_grad_norm_(lstm.parameters(), 10)\n",
    "\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    train_losses.append(np.mean(np.array(losses)))\n",
    "\n",
    "    losses = []\n",
    "    for i, (inputs, target) in enumerate(valid_loader):\n",
    "        inputs, target = inputs.cuda(), target.cuda()\n",
    "\n",
    "        model.eval()\n",
    "        valid, hidden = model(inputs)\n",
    "\n",
    "        #inverse\n",
    "        # valid = torch.from_numpy(scaler.inverse_transform(valid.cpu().detach().numpy()))\n",
    "\n",
    "\n",
    "        vall_loss = criterion(valid.squeeze(), target.float())\n",
    "        # scheduler.step(vall_loss)\n",
    "        losses.append(vall_loss.item())\n",
    "\n",
    "    valid_losses.append(np.mean(np.array(losses)))\n",
    "    \n",
    "    \n",
    "    if epoch % 2 == 0:\n",
    "        # print(criterion1(outputs, y_train.to(device),quantile))\n",
    "\n",
    "        print(\"Epoch: %d, loss: %1.5f valid loss:  %1.5f lr: %1.5f \" %(epoch, train_losses[-1],valid_losses[-1],\n",
    "                                                                        optimizer.param_groups[0][\"lr\"]))\n",
    "\n",
    "    torch.save(model.state_dict(), './model_weight.pth')\n",
    "    # model.load_state_dict(torch.load(SAVEPATH+'model_weight.pth'))\n",
    "\n",
    "    # early_stopping는 validation loss가 감소하였는지 확인이 필요하며,\n",
    "    # 만약 감소하였을경우 현제 모델을 checkpoint로 만든다.\n",
    "    \n",
    "    \"\"\"\n",
    "    early_stopping(round(valid_losses[-1],5), model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Epoch: %d, loss: %1.5f valid loss:  %1.5f lr: %1.5f \" %(epoch, train_losses[-1],valid_losses[-1],\n",
    "                                                                      optimizer.param_groups[0][\"lr\"]))\n",
    "        break\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c947f99-5f54-4ef6-8511-e149a59b1858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.3900e+02, 9.3500e+02, 2.0000e+00,  ..., 1.1120e+03, 6.5300e+02,\n",
      "         2.0000e+00],\n",
      "        [9.3900e+02, 9.3500e+02, 2.0000e+00,  ..., 1.1120e+03, 6.5300e+02,\n",
      "         2.0000e+00],\n",
      "        [9.3900e+02, 9.3500e+02, 2.0000e+00,  ..., 1.1120e+03, 6.5300e+02,\n",
      "         2.0000e+00],\n",
      "        ...,\n",
      "        [9.3900e+02, 9.3500e+02, 2.0000e+00,  ..., 1.0520e+03, 6.6400e+02,\n",
      "         2.0000e+00],\n",
      "        [9.3900e+02, 9.3500e+02, 2.0000e+00,  ..., 1.0520e+03, 6.6400e+02,\n",
      "         1.0000e+00],\n",
      "        [9.3900e+02, 9.3500e+02, 2.0000e+00,  ..., 1.0620e+03, 6.7000e+02,\n",
      "         1.0000e+00]])\n",
      "tensor(0, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "input, target = test_data[0]\n",
    "\n",
    "print(input)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9b68a9e-b20a-4704-9095-68b744e0c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val1 = None\n",
    "tor1 = None\n",
    "for i, (input, target) in enumerate(test_loader):\n",
    "    \n",
    "    input, target = input.cuda(), target.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    valid, hidden = model(input.to(device))\n",
    "    \n",
    "\n",
    "    #inverse\n",
    "    # valid = torch.from_numpy(scaler.inverse_transform(valid.cpu().detach().numpy()))\n",
    "\n",
    "    vall_loss = criterion(valid.squeeze(), target.float())\n",
    "    val1 = valid\n",
    "    tor1 = target.type(torch.long).to(device)\n",
    "    # scheduler.step(vall_loss)\n",
    "    losses.append(vall_loss.item())\n",
    "    \n",
    "\n",
    "#valid_losses.append(np.mean(np.array(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb99fee0-58b6-4574-a172-875f3d42785e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040,\n",
      "        0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040,\n",
      "        0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040, 0.4040,\n",
      "        0.4040, 0.4040, 0.4040, 0.4040], device='cuda:0',\n",
      "       grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(val1.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e2437a5-f7b8-42bc-b4f0-2ac669830ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(tor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93d66f7a-3e32-4ee8-98a4-729b5f686139",
   "metadata": {},
   "outputs": [],
   "source": [
    "vall_loss = criterion(val1.squeeze(), tor1.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b75cd47-4d67-4738-b7a3-21ff1aa98981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6680, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(vall_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "642b5693-0596-447e-8a89-f3f549c0d601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1264\n"
     ]
    }
   ],
   "source": [
    "print(len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb3e8f62-36a9-4716-9d8e-279d251bdfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20217\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b690af1-1e73-4c22-bf0a-fbf3556a60c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, criterion, optimizer,\n",
    "          epochs = 4, print_every = 1000, clip=5):\n",
    "    counter = 0\n",
    "\n",
    "    # move model to GPU, if available\n",
    "\n",
    "    model.train()\n",
    "    # train for some number of epochs\n",
    "    for e in range(epochs):\n",
    "      # batch loop\n",
    "        for inputs, labels in train_loader:\n",
    "            counter += 1\n",
    "\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # zero accumulated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # get the output from the model\n",
    "            output, h = model(inputs)\n",
    "\n",
    "            # calculate the loss and perform backprop\n",
    "            loss = criterion(output.squeeze(), labels.float())\n",
    "            loss.backward()\n",
    "\n",
    "            # `clip_grad_norm` helps prevent the exploding gradient problem\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss stats\n",
    "            if counter % print_every == 0:\n",
    "                # Get validation loss\n",
    "                val_losses = []\n",
    "                model.eval()\n",
    "                for inputs, labels in valid_loader:\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "                    output, val_h = model(inputs)\n",
    "                    val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                    val_losses.append(val_loss.item())\n",
    "\n",
    "                model.train()\n",
    "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                    \"Step: {}...\".format(counter),\n",
    "                    \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                    \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0862a49-db22-464c-9a77-178d7c0fdd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 1000... Loss: 0.713335... Val Loss: 0.665098\n",
      "Epoch: 1/4... Step: 2000... Loss: 0.665361... Val Loss: 0.667735\n",
      "Epoch: 1/4... Step: 3000... Loss: 0.697498... Val Loss: 0.680759\n",
      "Epoch: 1/4... Step: 4000... Loss: 0.680513... Val Loss: 0.668773\n",
      "Epoch: 1/4... Step: 5000... Loss: 0.647701... Val Loss: 0.657261\n",
      "Epoch: 1/4... Step: 6000... Loss: 0.644167... Val Loss: 0.657255\n",
      "Epoch: 1/4... Step: 7000... Loss: 0.622219... Val Loss: 0.663902\n",
      "Epoch: 2/4... Step: 8000... Loss: 0.679453... Val Loss: 0.661010\n",
      "Epoch: 2/4... Step: 9000... Loss: 0.582800... Val Loss: 0.676661\n",
      "Epoch: 2/4... Step: 10000... Loss: 0.775414... Val Loss: 0.687700\n",
      "Epoch: 2/4... Step: 11000... Loss: 0.627910... Val Loss: 0.657226\n",
      "Epoch: 2/4... Step: 12000... Loss: 0.676351... Val Loss: 0.666580\n",
      "Epoch: 2/4... Step: 13000... Loss: 0.667362... Val Loss: 0.705565\n",
      "Epoch: 2/4... Step: 14000... Loss: 0.632252... Val Loss: 0.657484\n",
      "Epoch: 2/4... Step: 15000... Loss: 0.530082... Val Loss: 0.682073\n",
      "Epoch: 3/4... Step: 16000... Loss: 0.589778... Val Loss: 0.677729\n",
      "Epoch: 3/4... Step: 17000... Loss: 0.643803... Val Loss: 0.666336\n",
      "Epoch: 3/4... Step: 18000... Loss: 0.644069... Val Loss: 0.657259\n",
      "Epoch: 3/4... Step: 19000... Loss: 0.708913... Val Loss: 0.683691\n",
      "Epoch: 3/4... Step: 20000... Loss: 0.688083... Val Loss: 0.693358\n",
      "Epoch: 3/4... Step: 21000... Loss: 0.701307... Val Loss: 0.658123\n",
      "Epoch: 3/4... Step: 22000... Loss: 0.678195... Val Loss: 0.668234\n",
      "Epoch: 3/4... Step: 23000... Loss: 0.814055... Val Loss: 0.657435\n",
      "Epoch: 4/4... Step: 24000... Loss: 0.661593... Val Loss: 0.659135\n",
      "Epoch: 4/4... Step: 25000... Loss: 0.718507... Val Loss: 0.657538\n",
      "Epoch: 4/4... Step: 26000... Loss: 0.671166... Val Loss: 0.659374\n",
      "Epoch: 4/4... Step: 27000... Loss: 0.594164... Val Loss: 0.669988\n",
      "Epoch: 4/4... Step: 28000... Loss: 0.715163... Val Loss: 0.658636\n",
      "Epoch: 4/4... Step: 29000... Loss: 0.700298... Val Loss: 0.661024\n",
      "Epoch: 4/4... Step: 30000... Loss: 0.667254... Val Loss: 0.660296\n",
      "Epoch: 4/4... Step: 31000... Loss: 0.626795... Val Loss: 0.660524\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, valid_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4866683a-25c7-4da4-aa61-cdce47cc0c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, sequence_length=30):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    batch_size = 32\n",
    "    acc_list = list()\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        \n",
    "        output, h = model(inputs)\n",
    "        \n",
    "        pred = torch.round(output.squeeze())\n",
    "        \n",
    "        accuracy = (pred==labels).sum().item() / 32\n",
    "        acc_list.append(accuracy)\n",
    "\n",
    "        #print('Prediction value, pre-rounding: ', output.item())\n",
    "\n",
    "        # print custom response based on whether test_review is pos/neg\n",
    "        \n",
    "    print(np.mean(acc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c119dffe-7a10-4778-87f3-d85b17b0f4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63454417773238\n"
     ]
    }
   ],
   "source": [
    "predict(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0fb27-b66c-480a-bb39-16f0740eac18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
